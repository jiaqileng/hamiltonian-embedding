{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.sparse.linalg import expm_multiply, expm\n",
    "from scipy.sparse import diags\n",
    "\n",
    "from os.path import join, dirname\n",
    "import sys\n",
    "sys.path.append(join(\".\", \"..\"))\n",
    "from ionq_circuit_utils import *\n",
    "\n",
    "import sys\n",
    "sys.path.append(join(\".\", \"..\", \"..\"))\n",
    "from utils import *\n",
    "\n",
    "import json\n",
    "import hashlib\n",
    "\n",
    "import networkx as nx\n",
    "from random import shuffle, seed\n",
    "\n",
    "from braket.devices import LocalSimulator\n",
    "\n",
    "from qiskit import QuantumCircuit, transpile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantum walk circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qw_circuit(graph, t, r):\n",
    "\n",
    "    # Returns Trotterized circuit for quantum walk on graph using one-hot embedding\n",
    "\n",
    "    line_graph = nx.line_graph(graph)\n",
    "    coloring = nx.coloring.greedy_color(line_graph, strategy=\"independent_set\")\n",
    "\n",
    "    coloring_grouped = {}\n",
    "    for edge in coloring.keys():\n",
    "        if coloring[edge] in coloring_grouped:\n",
    "            coloring_grouped[coloring[edge]].append(edge)\n",
    "        else:\n",
    "            coloring_grouped[coloring[edge]] = [edge]\n",
    "\n",
    "    num_colors = len(coloring_grouped.keys())\n",
    "\n",
    "    instructions = []\n",
    "\n",
    "    # Use randomized first order Trotter\n",
    "    dt = t / r\n",
    "    \n",
    "    np.random.seed(int(t * r))\n",
    "    for _ in range(r):\n",
    "        if np.random.rand() < 0.5:\n",
    "            for color in np.arange(0, num_colors):\n",
    "                edge_list = coloring_grouped[color]\n",
    "                \n",
    "                for i,j in edge_list:\n",
    "                    instructions.append(get_rxx(dt, targets=[int(i),int(j)]))\n",
    "                    instructions.append(get_ryy(dt, targets=[int(i),int(j)]))\n",
    "        else:\n",
    "            for color in np.arange(0, num_colors)[::-1]:\n",
    "                edge_list = coloring_grouped[color]\n",
    "                \n",
    "                for i,j in edge_list:\n",
    "                    instructions.append(get_ryy(dt, targets=[int(i),int(j)]))\n",
    "                    instructions.append(get_rxx(dt, targets=[int(i),int(j)]))\n",
    "    return instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_qw(N, dimension, n, encoding, bitstrings, num_time_points, graph, t_vals, task_name, \n",
    "           vertex, r, num_shots, device, save_dir, use_real_machine, qpu_job_ids_filename):\n",
    "    assert encoding == \"one-hot\"\n",
    "\n",
    "    job_ids = []\n",
    "    task_arns = []\n",
    "\n",
    "    # unnormalized probabilities\n",
    "    sim_freq = np.zeros((num_time_points, N))\n",
    "    dimension = 1\n",
    "\n",
    "    for i, t in enumerate(t_vals):\n",
    "        \n",
    "        print(f\"Unitless time: {t : 0.3f}\")\n",
    "\n",
    "        # Construct the circuit\n",
    "        instructions = []\n",
    "\n",
    "        # Initial state preparation: start from root node\n",
    "        instructions.append(get_rx(np.pi, vertex))\n",
    "        if t > 0:\n",
    "            instructions += get_qw_circuit(graph, t, r)\n",
    "\n",
    "        if use_real_machine:\n",
    "\n",
    "            # Create the job json and save it\n",
    "            job = get_ionq_job_json(task_name, N, dimension, num_shots, device, encoding, instructions, use_native_gates=True)\n",
    "            \n",
    "            print(f\"Saving in {save_dir}\")\n",
    "            with open(join(save_dir, f\"job_{i}.json\"), \"w\") as f:\n",
    "                json.dump(job, f, default=int)\n",
    "\n",
    "            # Send the job and get the job id\n",
    "            job_id = send_job(job)\n",
    "            print(\"Job id:\", job_id)\n",
    "            job_ids.append(job_id)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            native_instructions, qubit_phase = get_native_circuit(n, instructions)\n",
    "            one_qubit_gate_count, two_qubit_gate_count = get_native_gate_counts(native_instructions)\n",
    "            print(f\"1q gates: {one_qubit_gate_count}, 2q gates: {two_qubit_gate_count}\")\n",
    "            circuit = get_braket_native_circuit(native_instructions)\n",
    "            for j in range(n * dimension):\n",
    "                circuit.rz(j, -qubit_phase[j] * (2 * np.pi))\n",
    "\n",
    "            circuit.amplitude(state=bitstrings)\n",
    "\n",
    "            # Run on simulator\n",
    "            task = device.run(circuit)\n",
    "\n",
    "            if device.name == \"SV1\":\n",
    "                # Save the data\n",
    "                metadata = task.metadata()\n",
    "                task_arn = metadata['quantumTaskArn']\n",
    "                task_arns.append(task_arn)\n",
    "                print(f\"ARN: {task_arn}\")\n",
    "            else:\n",
    "                amplitudes = task.result().values[0]\n",
    "                for j in range(N ** dimension):\n",
    "                    sim_freq[i,j] = np.abs(amplitudes[bitstrings[j]]) ** 2\n",
    "\n",
    "    if use_real_machine:\n",
    "        print(f\"Saving IonQ job ids as {qpu_job_ids_filename}\")\n",
    "        with open(join(save_dir, qpu_job_ids_filename), \"w\") as f:\n",
    "            json.dump(job_ids, f)\n",
    "            f.close()\n",
    "    else:\n",
    "        return sim_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum walk on 1D chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"experiment_data\"\n",
    "TASK_DIR = \"1d_chain\"\n",
    "\n",
    "CURR_DIR = join(\"..\", \"..\", \"..\", DATA_DIR)\n",
    "check_and_make_dir(CURR_DIR)\n",
    "CURR_DIR = join(CURR_DIR, TASK_DIR)\n",
    "check_and_make_dir(CURR_DIR)\n",
    "\n",
    "print(CURR_DIR)\n",
    "\n",
    "use_real_machine = False\n",
    "if use_real_machine:\n",
    "    device = \"qpu.aria-1\"\n",
    "    print(\"Device:\", device)\n",
    "else:\n",
    "    device = LocalSimulator()\n",
    "    print(f\"Using {device.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 15\n",
    "r = 5\n",
    "\n",
    "dimension = 1\n",
    "encoding = \"one-hot\"\n",
    "n = num_qubits_per_dim(N, encoding)\n",
    "codewords = get_codewords_1d(n, encoding, periodic=False)\n",
    "bitstrings = get_bitstrings(N, dimension, encoding)\n",
    "T = 4.0\n",
    "num_time_points = 17\n",
    "t_vals = np.linspace(0, T, num_time_points)\n",
    "\n",
    "# Trotter steps\n",
    "num_shots = 200\n",
    "vertex = int(N/2)\n",
    "\n",
    "use_error_mitigation = False\n",
    "\n",
    "if use_error_mitigation:\n",
    "    assert num_shots >= 500, \"Number of shots should be at least 500\"\n",
    "\n",
    "experiment_info = {\n",
    "    \"N\": N,\n",
    "    \"dimension\": dimension,\n",
    "    \"encoding\": encoding,\n",
    "    \"T\": T,\n",
    "    \"num_time_points\": num_time_points,\n",
    "    \"r\": r,\n",
    "    \"num_shots\": num_shots,\n",
    "    \"vertex\": vertex,\n",
    "    \"use_error_mitigation\": use_error_mitigation\n",
    "}\n",
    "\n",
    "hash_str = hashlib.md5(json.dumps(experiment_info).encode(\"utf-8\")).hexdigest()\n",
    "SAVE_DIR = join(CURR_DIR, hash_str)\n",
    "check_and_make_dir(SAVE_DIR)\n",
    "\n",
    "print(\"Save dir:\", SAVE_DIR)\n",
    "\n",
    "with open(join(SAVE_DIR, \"experiment_info.json\"), \"w\") as f:\n",
    "    json.dump(experiment_info, f)\n",
    "    f.close()\n",
    "\n",
    "graph = nx.path_graph(N)\n",
    "\n",
    "A = nx.adjacency_matrix(graph, nodelist=sorted(graph.nodes()))\n",
    "\n",
    "print(\"Two qubit gate count:\", graph.size() * 2 * r)\n",
    "\n",
    "qpu_job_ids_filename = 'job_ids_qpu.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_real_machine:\n",
    "    run_qw(N, dimension, n, encoding, bitstrings, num_time_points, graph, t_vals, TASK_DIR, vertex, r, num_shots, device, SAVE_DIR, use_real_machine, qpu_job_ids_filename)\n",
    "else:\n",
    "    sim_freq = run_qw(N, dimension, n, encoding, bitstrings, num_time_points, graph, t_vals, TASK_DIR, vertex, r, num_shots, device, SAVE_DIR, use_real_machine, qpu_job_ids_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ionq_freq = get_results(join(SAVE_DIR, qpu_job_ids_filename), num_time_points, codewords, use_error_mitigation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post processing and figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_freq_normalized = np.zeros_like(sim_freq)\n",
    "for i in range(num_time_points):\n",
    "    if np.sum(sim_freq[i]) > 0:\n",
    "        sim_freq_normalized[i] = sim_freq[i] / np.sum(sim_freq[i])\n",
    "\n",
    "ionq_freq_normalized = np.zeros_like(ionq_freq)\n",
    "for i in range(num_time_points):\n",
    "    if np.sum(ionq_freq[i]) > 0:\n",
    "        ionq_freq_normalized[i] = ionq_freq[i] / np.sum(ionq_freq[i])\n",
    "\n",
    "num_samples_subspace_ionq = np.sum(ionq_freq, axis=1) * num_shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "psi_0 = np.zeros(N)\n",
    "psi_0[vertex] = 1\n",
    "\n",
    "psi = expm_multiply(-1j * A, psi_0, start=0, stop=T, num=num_time_points)\n",
    "ideal_dist = np.abs(psi) ** 2\n",
    "\n",
    "distance_vec = np.abs(np.arange(-int(N/2), int((N+1)/2)))\n",
    "\n",
    "# Compute propagation distance\n",
    "propagation_distance_ideal = ideal_dist @ distance_vec\n",
    "propagation_distance_sim = sim_freq_normalized @ distance_vec\n",
    "propagation_distance_ionq = ionq_freq_normalized @ distance_vec\n",
    "\n",
    "# Using unbiased sample variance to compute standard error\n",
    "propagation_distance_ionq_err = np.array(\n",
    "    [np.sqrt(ionq_freq_normalized[i] @ (distance_vec - propagation_distance_ionq[i]) ** 2 / (num_samples_subspace_ionq[i] - 1)) for i in range(num_time_points)]\n",
    ")\n",
    "\n",
    "valid_points_ionq = np.sum(ionq_freq, axis=1) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(TASK_DIR, \"experiment_info.json\"), \"w\") as f:\n",
    "    json.dump(experiment_info, f)\n",
    "    f.close()\n",
    "    \n",
    "np.savez(join(TASK_DIR, \"data.npz\"), \n",
    "         ideal_dist=ideal_dist,                                         # Ideal QW\n",
    "         sim_freq=sim_freq,                                             # Simulator with Hamiltonian embedding\n",
    "         ionq_freq_normalized=ionq_freq_normalized,                     # IonQ (normalized)\n",
    "         propagation_distance_ideal=propagation_distance_ideal,         # Propagation distance\n",
    "         propagation_distance_sim=propagation_distance_sim,\n",
    "         propagation_distance_ionq=propagation_distance_ionq,\n",
    "         propagation_distance_ionq_err=propagation_distance_ionq_err,   # Propagation distance std error\n",
    "         ionq_freq=ionq_freq,                                           # IonQ frequency (unnormalized)\n",
    "         num_samples_subspace_ionq=num_samples_subspace_ionq)           # Samples in encoding subspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum walk on 1D cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"experiment_data\"\n",
    "TASK_DIR = \"1d_cycle\"\n",
    "\n",
    "CURR_DIR = join(\"..\", \"..\", \"..\", DATA_DIR)\n",
    "check_and_make_dir(CURR_DIR)\n",
    "CURR_DIR = join(CURR_DIR, TASK_DIR)\n",
    "check_and_make_dir(CURR_DIR)\n",
    "\n",
    "print(CURR_DIR)\n",
    "\n",
    "use_real_machine = False\n",
    "if use_real_machine:\n",
    "    device = \"qpu.aria-1\"\n",
    "    # device = \"simulator\"\n",
    "    print(\"Device:\", device)\n",
    "else:\n",
    "    device = LocalSimulator()\n",
    "\n",
    "    print(f\"Using {device.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 15\n",
    "r = 5\n",
    "\n",
    "dimension = 1\n",
    "encoding = \"one-hot\"\n",
    "n = num_qubits_per_dim(N, encoding)\n",
    "codewords = get_codewords_1d(n, encoding, periodic=False)\n",
    "bitstrings = get_bitstrings(N, dimension, encoding)\n",
    "T = 4.0\n",
    "num_time_points = 17\n",
    "t_vals = np.linspace(0, T, num_time_points)\n",
    "\n",
    "# Trotter steps\n",
    "num_shots = 200\n",
    "vertex = int(N/2)\n",
    "\n",
    "use_error_mitigation = False\n",
    "\n",
    "if use_error_mitigation:\n",
    "    assert num_shots >= 500, \"Number of shots should be at least 500\"\n",
    "\n",
    "experiment_info = {\n",
    "    \"N\": N,\n",
    "    \"dimension\": dimension,\n",
    "    \"encoding\": encoding,\n",
    "    \"T\": T,\n",
    "    \"num_time_points\": num_time_points,\n",
    "    \"r\": r,\n",
    "    \"num_shots\": num_shots,\n",
    "    \"vertex\": vertex,\n",
    "    \"use_error_mitigation\": use_error_mitigation\n",
    "}\n",
    "\n",
    "hash_str = hashlib.md5(json.dumps(experiment_info).encode(\"utf-8\")).hexdigest()\n",
    "SAVE_DIR = join(CURR_DIR, hash_str)\n",
    "check_and_make_dir(SAVE_DIR)\n",
    "\n",
    "print(\"Save dir:\", SAVE_DIR)\n",
    "\n",
    "with open(join(SAVE_DIR, \"experiment_info.json\"), \"w\") as f:\n",
    "    json.dump(experiment_info, f)\n",
    "    f.close()\n",
    "\n",
    "graph = nx.cycle_graph(N)\n",
    "\n",
    "A = nx.adjacency_matrix(graph, nodelist=sorted(graph.nodes()))\n",
    "\n",
    "print(\"Two qubit gate count:\", graph.size() * 2 * r)\n",
    "\n",
    "qpu_job_ids_filename = 'job_ids_qpu.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_real_machine:\n",
    "    run_qw(N, dimension, n, encoding, bitstrings, num_time_points, graph, t_vals, TASK_DIR, vertex, r, num_shots, device, SAVE_DIR, use_real_machine, qpu_job_ids_filename)\n",
    "else:\n",
    "    sim_freq = run_qw(N, dimension, n, encoding, bitstrings, num_time_points, graph, t_vals, TASK_DIR, vertex, r, num_shots, device, SAVE_DIR, use_real_machine, qpu_job_ids_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ionq_freq = get_results(join(SAVE_DIR, qpu_job_ids_filename), num_time_points, codewords, use_error_mitigation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figures and post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_freq_normalized = np.zeros_like(sim_freq)\n",
    "for i in range(num_time_points):\n",
    "    if np.sum(sim_freq[i]) > 0:\n",
    "        sim_freq_normalized[i] = sim_freq[i] / np.sum(sim_freq[i])\n",
    "\n",
    "ionq_freq_normalized = np.zeros_like(ionq_freq)\n",
    "for i in range(num_time_points):\n",
    "    if np.sum(ionq_freq[i]) > 0:\n",
    "        ionq_freq_normalized[i] = ionq_freq[i] / np.sum(ionq_freq[i])\n",
    "\n",
    "num_samples_subspace_ionq = np.sum(ionq_freq, axis=1) * num_shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "psi_0 = np.zeros(N)\n",
    "psi_0[vertex] = 1\n",
    "\n",
    "psi = expm_multiply(-1j * A, psi_0, start=0, stop=T, num=num_time_points)\n",
    "ideal_dist = np.abs(psi) ** 2\n",
    "\n",
    "distance_vec = np.abs(np.arange(-int(N/2), int((N+1)/2)))\n",
    "\n",
    "# Compute propagation distance\n",
    "propagation_distance_ideal = ideal_dist @ distance_vec\n",
    "propagation_distance_sim = sim_freq_normalized @ distance_vec\n",
    "propagation_distance_ionq = ionq_freq_normalized @ distance_vec\n",
    "\n",
    "# Using unbiased sample variance to compute standard error\n",
    "propagation_distance_ionq_err = np.array(\n",
    "    [np.sqrt(ionq_freq_normalized[i] @ (distance_vec - propagation_distance_ionq[i]) ** 2 / (num_samples_subspace_ionq[i] - 1)) for i in range(num_time_points)]\n",
    ")\n",
    "\n",
    "valid_points_ionq = np.sum(ionq_freq, axis=1) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(TASK_DIR, \"experiment_info.json\"), \"w\") as f:\n",
    "    json.dump(experiment_info, f)\n",
    "    f.close()\n",
    "    \n",
    "np.savez(join(TASK_DIR, \"data.npz\"), \n",
    "         ideal_dist=ideal_dist,                                         # Ideal QW\n",
    "         sim_freq=sim_freq,                                             # Simulator with Hamiltonian embedding\n",
    "         ionq_freq_normalized=ionq_freq_normalized,                     # IonQ (normalized)\n",
    "         propagation_distance_ideal=propagation_distance_ideal,         # Propagation distance\n",
    "         propagation_distance_sim=propagation_distance_sim,\n",
    "         propagation_distance_ionq=propagation_distance_ionq,\n",
    "         propagation_distance_ionq_err=propagation_distance_ionq_err,   # Propagation distance std error\n",
    "         ionq_freq=ionq_freq,                                           # IonQ frequency (unnormalized)\n",
    "         num_samples_subspace_ionq=num_samples_subspace_ionq)           # Samples in encoding subspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum walk on binary tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_tree(N):\n",
    "    graph = nx.Graph()\n",
    "    for i in np.arange(1, N):\n",
    "        graph.add_edge(int((i-1)/2), int(i))\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"experiment_data\"\n",
    "TASK_DIR = \"binary_tree\"\n",
    "\n",
    "CURR_DIR = join(\"..\", \"..\", \"..\", DATA_DIR)\n",
    "check_and_make_dir(CURR_DIR)\n",
    "CURR_DIR = join(CURR_DIR, TASK_DIR)\n",
    "check_and_make_dir(CURR_DIR)\n",
    "\n",
    "print(CURR_DIR)\n",
    "\n",
    "use_real_machine = False\n",
    "if use_real_machine:\n",
    "    device = \"qpu.aria-1\"\n",
    "    print(\"Device:\", device)\n",
    "else:\n",
    "    device = LocalSimulator()\n",
    "\n",
    "    print(f\"Using {device.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 15\n",
    "dimension = 1\n",
    "encoding = \"one-hot\"\n",
    "n = num_qubits_per_dim(N, encoding)\n",
    "codewords = get_codewords_1d(n, encoding, periodic=False)\n",
    "bitstrings = get_bitstrings(N, dimension, encoding)\n",
    "T = 3.0\n",
    "num_time_points = 16\n",
    "t_vals = np.linspace(0, T, num_time_points)\n",
    "\n",
    "# Trotter steps\n",
    "r = 6\n",
    "num_shots = 200\n",
    "vertex = 0\n",
    "\n",
    "use_error_mitigation = False\n",
    "\n",
    "if use_error_mitigation:\n",
    "    assert num_shots >= 500, \"Number of shots should be at least 500\"\n",
    "\n",
    "experiment_info = {\n",
    "    \"N\": N,\n",
    "    \"dimension\": dimension,\n",
    "    \"encoding\": encoding,\n",
    "    \"T\": T,\n",
    "    \"num_time_points\": num_time_points,\n",
    "    \"r\": r,\n",
    "    \"num_shots\": num_shots,\n",
    "    \"vertex\": vertex,\n",
    "    \"use_error_mitigation\": use_error_mitigation\n",
    "}\n",
    "\n",
    "hash_str = hashlib.md5(json.dumps(experiment_info).encode(\"utf-8\")).hexdigest()\n",
    "SAVE_DIR = join(CURR_DIR, hash_str)\n",
    "check_and_make_dir(SAVE_DIR)\n",
    "\n",
    "print(\"Save dir:\", SAVE_DIR)\n",
    "\n",
    "with open(join(SAVE_DIR, \"experiment_info.json\"), \"w\") as f:\n",
    "    json.dump(experiment_info, f)\n",
    "    f.close()\n",
    "\n",
    "    \n",
    "# Create binary tree with N nodes\n",
    "graph = get_binary_tree(N)\n",
    "\n",
    "A = nx.adjacency_matrix(graph, nodelist=sorted(graph.nodes()))\n",
    "\n",
    "print(\"Two qubit gate count:\", graph.size() * 2 * r)\n",
    "\n",
    "qpu_job_ids_filename = \"job_ids_qpu.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_real_machine:\n",
    "    run_qw(N, dimension, n, encoding, bitstrings, num_time_points, graph, t_vals, TASK_DIR, vertex, r, num_shots, device, SAVE_DIR, use_real_machine, qpu_job_ids_filename)\n",
    "else:\n",
    "    sim_freq = run_qw(N, dimension, n, encoding, bitstrings, num_time_points, graph, t_vals, TASK_DIR, vertex, r, num_shots, device, SAVE_DIR, use_real_machine, qpu_job_ids_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ionq_freq = get_results(join(SAVE_DIR, qpu_job_ids_filename), num_time_points, codewords, use_error_mitigation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post processing and figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_freq_normalized = np.zeros_like(sim_freq)\n",
    "for i in range(num_time_points):\n",
    "    if np.sum(sim_freq[i]) > 0:\n",
    "        sim_freq_normalized[i] = sim_freq[i] / np.sum(sim_freq[i])\n",
    "\n",
    "ionq_freq_normalized = np.zeros_like(ionq_freq)\n",
    "for i in range(num_time_points):\n",
    "    if np.sum(ionq_freq[i]) > 0:\n",
    "        ionq_freq_normalized[i] = ionq_freq[i] / np.sum(ionq_freq[i])\n",
    "\n",
    "num_samples_subspace_ionq = np.sum(ionq_freq, axis=1) * num_shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "psi_0 = np.zeros(N)\n",
    "psi_0[vertex] = 1\n",
    "\n",
    "psi = expm_multiply(-1j * A, psi_0, start=0, stop=T, num=num_time_points)\n",
    "ideal_dist = np.abs(psi) ** 2\n",
    "\n",
    "distance_vec = np.zeros(N)\n",
    "for i in range(N):\n",
    "    distance_vec[i] = int(np.log2(i + 1))\n",
    "\n",
    "# Compute propagation distance\n",
    "propagation_distance_ideal = ideal_dist @ distance_vec\n",
    "propagation_distance_sim = sim_freq_normalized @ distance_vec\n",
    "propagation_distance_ionq = ionq_freq_normalized @ distance_vec\n",
    "\n",
    "# Using unbiased sample variance\n",
    "propagation_distance_ionq_err = np.array(\n",
    "    [np.sqrt(ionq_freq_normalized[i] @ (distance_vec - propagation_distance_ionq[i]) ** 2 / (num_samples_subspace_ionq[i] - 1)) for i in range(num_time_points)]\n",
    ")\n",
    "\n",
    "valid_points_ionq = np.sum(ionq_freq, axis=1) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(TASK_DIR, \"experiment_info.json\"), \"w\") as f:\n",
    "    json.dump(experiment_info, f)\n",
    "    f.close()\n",
    "    \n",
    "np.savez(join(TASK_DIR, \"data.npz\"), \n",
    "         ideal_dist=ideal_dist,                                         # Ideal QW\n",
    "         sim_freq=sim_freq,                                             # Simulator with Hamiltonian embedding\n",
    "         ionq_freq_normalized=ionq_freq_normalized,                     # IonQ (normalized)\n",
    "         propagation_distance_ideal=propagation_distance_ideal,         # Propagation distance\n",
    "         propagation_distance_sim=propagation_distance_sim,\n",
    "         propagation_distance_ionq=propagation_distance_ionq,\n",
    "         propagation_distance_ionq_err=propagation_distance_ionq_err,   # Propagation distance std error\n",
    "         ionq_freq=ionq_freq,                                           # IonQ frequency (unnormalized)\n",
    "         num_samples_subspace_ionq=num_samples_subspace_ionq)           # Samples in encoding subspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum walk on glued trees graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"experiment_data\"\n",
    "TASK_DIR = \"glued_trees\"\n",
    "\n",
    "CURR_DIR = join(\"..\", \"..\", \"..\", DATA_DIR)\n",
    "check_and_make_dir(CURR_DIR)\n",
    "CURR_DIR = join(CURR_DIR, TASK_DIR)\n",
    "check_and_make_dir(CURR_DIR)\n",
    "\n",
    "print(CURR_DIR)\n",
    "\n",
    "use_real_machine = False\n",
    "if use_real_machine:\n",
    "    device = \"qpu.aria-1\"\n",
    "    print(\"Device:\", device)\n",
    "else:\n",
    "    device = LocalSimulator()\n",
    "    print(f\"Using {device.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glued_tree(h):\n",
    "    seed(0)\n",
    "    # Two binary trees of height h (2^(h+1) - 1 nodes each glued together\n",
    "    num_nodes_per_binary_tree = 2 ** (h+1) - 1\n",
    "    num_nodes = 2 * num_nodes_per_binary_tree\n",
    "    graph = nx.Graph()\n",
    "\n",
    "    # Leaves\n",
    "    leaves_first = []\n",
    "    leaves_second = []\n",
    "    for i in range(2 ** h):\n",
    "        leaves_first.append(2 ** h - 1 + i)\n",
    "        leaves_second.append(num_nodes - 1 - (2 ** h - 1) - i)\n",
    "\n",
    "    for i in np.arange(1, num_nodes_per_binary_tree):\n",
    "\n",
    "        # First binary tree\n",
    "        graph.add_edge(int((i-1)/2), int(i))\n",
    "\n",
    "        # Second binary tree\n",
    "        graph.add_edge(int(num_nodes - 1 - int((i-1)/2)), int(num_nodes - 1 - i))\n",
    "\n",
    "    # Glue the two trees together\n",
    "    # Shuffle the leaves to get a random cycle\n",
    "    shuffle(leaves_first)\n",
    "    shuffle(leaves_second)\n",
    "\n",
    "    for i in range(2 ** h):\n",
    "        graph.add_edge(int(leaves_first[i]), int(leaves_second[i]))\n",
    "        graph.add_edge(int(leaves_second[i]), int(leaves_first[(i+1) % (2 ** h)]))\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glued_tree_height = 2\n",
    "N = 2 * (2 ** (glued_tree_height + 1) - 1)\n",
    "print(f\"Nodes in graph: {N}\")\n",
    "\n",
    "dimension = 1\n",
    "encoding = \"one-hot\"\n",
    "n = num_qubits_per_dim(N, encoding=encoding)\n",
    "codewords = get_codewords_1d(n, encoding, periodic=False)\n",
    "bitstrings = get_bitstrings(N, dimension, encoding)\n",
    "\n",
    "T = 2\n",
    "r = 4\n",
    "\n",
    "num_time_points = 11\n",
    "t_vals = np.linspace(0, T, num_time_points)\n",
    "\n",
    "num_shots = 200\n",
    "vertex = 0\n",
    "\n",
    "use_error_mitigation = False\n",
    "\n",
    "if use_error_mitigation:\n",
    "    assert num_shots >= 500, \"Number of shots should be at least 500\"\n",
    "\n",
    "experiment_info = {\n",
    "    \"N\": N,\n",
    "    \"dimension\": dimension,\n",
    "    \"encoding\": encoding,\n",
    "    \"T\": T,\n",
    "    \"num_time_points\": num_time_points,\n",
    "    \"r\": r,\n",
    "    \"num_shots\": num_shots,\n",
    "    \"vertex\": vertex,\n",
    "    \"use_error_mitigation\": use_error_mitigation,\n",
    "}\n",
    "\n",
    "hash_str = hashlib.md5(json.dumps(experiment_info).encode(\"utf-8\")).hexdigest()\n",
    "SAVE_DIR = join(CURR_DIR, hash_str)\n",
    "check_and_make_dir(SAVE_DIR)\n",
    "print(\"Save dir:\", SAVE_DIR)\n",
    "\n",
    "with open(join(SAVE_DIR, \"experiment_info.json\"), \"w\") as f:\n",
    "    json.dump(experiment_info, f)\n",
    "    f.close()\n",
    "    \n",
    "graph = get_glued_tree(glued_tree_height)\n",
    "\n",
    "nx.draw(graph, with_labels=True)\n",
    "A = nx.adjacency_matrix(graph, nodelist=sorted(graph.nodes()))\n",
    "\n",
    "print(\"Two qubit gate count:\", graph.size() * r * 2)\n",
    "\n",
    "qpu_job_ids_filename = 'job_ids_qpu.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_real_machine:\n",
    "    run_qw(N, dimension, n, encoding, bitstrings, num_time_points, graph, t_vals, TASK_DIR, vertex, r, num_shots, device, SAVE_DIR, use_real_machine, qpu_job_ids_filename)\n",
    "else:\n",
    "    sim_freq = run_qw(N, dimension, n, encoding, bitstrings, num_time_points, graph, t_vals, TASK_DIR, vertex, r, num_shots, device, SAVE_DIR, use_real_machine, qpu_job_ids_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data from completed tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ionq_freq = get_results(join(SAVE_DIR, qpu_job_ids_filename), num_time_points, codewords, use_error_mitigation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post processing and figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ionq_freq_normalized = np.zeros_like(ionq_freq)\n",
    "for i in range(num_time_points):\n",
    "    if np.sum(ionq_freq[i]) > 0:\n",
    "        ionq_freq_normalized[i] = ionq_freq[i] / np.sum(ionq_freq[i])\n",
    "\n",
    "num_samples_subspace_ionq = np.sum(ionq_freq, axis=1) * num_shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "psi_0 = np.zeros(N)\n",
    "psi_0[vertex] = 1\n",
    "\n",
    "psi = expm_multiply(-1j * A, psi_0, start=0, stop=T, num=num_time_points)\n",
    "ideal_dist = np.abs(psi) ** 2\n",
    "\n",
    "def get_glued_tree_distance_vec(glued_tree_height):\n",
    "    \n",
    "    distance_vec = np.zeros(N)\n",
    "    for i in range(2 ** (glued_tree_height + 1) - 1):\n",
    "        distance_vec[i] = int(np.log2(i + 1))\n",
    "    for i in np.arange(2 ** (glued_tree_height + 1) - 1, N):\n",
    "        distance_vec[i] = 2 * (glued_tree_height + 1) - 1 - int(np.log2(N - i))\n",
    "\n",
    "    return distance_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(TASK_DIR, \"experiment_info.json\"), \"w\") as f:\n",
    "    json.dump(experiment_info, f)\n",
    "    f.close()\n",
    "\n",
    "np.savez(join(TASK_DIR, \"data.npz\"), \n",
    "         ideal_dist=ideal_dist,\n",
    "         sim_freq=sim_freq,\n",
    "         ionq_freq=ionq_freq,\n",
    "         ionq_freq_normalized=ionq_freq_normalized,\n",
    "         num_samples_subspace_ionq=num_samples_subspace_ionq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
