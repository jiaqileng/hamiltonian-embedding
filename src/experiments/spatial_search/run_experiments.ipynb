{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.sparse.linalg import expm_multiply, expm\n",
    "from scipy.sparse import diags\n",
    "\n",
    "from os.path import join, dirname\n",
    "import sys\n",
    "sys.path.append(join(\".\", \"..\"))\n",
    "from ionq_circuit_utils import *\n",
    "\n",
    "import sys\n",
    "sys.path.append(join(\".\", \"..\", \"..\"))\n",
    "from utils import *\n",
    "\n",
    "import json\n",
    "import hashlib\n",
    "\n",
    "import networkx as nx\n",
    "from random import shuffle, seed\n",
    "\n",
    "from braket.devices import LocalSimulator\n",
    "\n",
    "from qiskit import QuantumCircuit, transpile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial search circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spatial_search_circuit(N, lamb, gamma, t, r, encoding, use_second_order_pf=False):\n",
    "    n = num_qubits_per_dim(N, encoding)\n",
    "    dimension = 2\n",
    "    instructions = []\n",
    "\n",
    "    dt = t / r\n",
    "    np.random.seed(int(t * r))\n",
    "\n",
    "    if encoding == \"unary\" or encoding == \"antiferromagnetic\":\n",
    "        instructions += get_hadamard_layer(n, dimension)\n",
    "\n",
    "        for _ in range(r):\n",
    "            if use_second_order_pf:\n",
    "                # X rotations (between hadamard)\n",
    "                for i in range(dimension * n):\n",
    "                    instructions.append(get_rz(- gamma * dt, i))\n",
    "\n",
    "                # penalty term\n",
    "                for i in range(dimension):\n",
    "                    instructions.append(get_rx(2 * lamb * dt, i * n))\n",
    "                    if encoding == \"unary\":\n",
    "                        instructions.append(get_rx(-2 * lamb * dt, int((i + 1) * n - 1)))\n",
    "                    if encoding == \"antiferromagnetic\":\n",
    "                        instructions.append(get_rx((-1) ** (n) * 2 * lamb * dt, int((i + 1) * n - 1)))\n",
    "                    \n",
    "                    for j in np.arange(i * n, (i + 1) * n - 1):\n",
    "                        if encoding == \"unary\":\n",
    "                            instructions.append(get_rxx(-2 * lamb * dt, [int(j), int(j+1)]))\n",
    "                        elif encoding == \"antiferromagnetic\":\n",
    "                            instructions.append(get_rxx(2 * lamb * dt, [int(j), int(j+1)]))\n",
    "\n",
    "                # oracle term\n",
    "                instructions.append(get_rxx(dt / 2, [int(n-1), int(n)]))\n",
    "                instructions.append(get_rx(dt / 2, n-1))\n",
    "                instructions.append(get_rx(- dt / 2, n))\n",
    "\n",
    "                # laplacian correction term\n",
    "                for i in range(dimension):\n",
    "                    instructions.append(get_rx(-gamma * dt, i * n))\n",
    "                    if encoding == \"unary\":\n",
    "                        instructions.append(get_rx(gamma * dt, int((i + 1) * n - 1)))\n",
    "                    elif encoding == \"antiferromagnetic\":\n",
    "                        instructions.append(get_rx((-1) ** (n+1) * gamma * dt, int((i + 1) * n - 1)))\n",
    "                \n",
    "                # X rotations (between hadamard)\n",
    "                for i in range(dimension * n):\n",
    "                    instructions.append(get_rz(- gamma * dt, i))\n",
    "            else:\n",
    "                # Use randomized first order\n",
    "                if np.random.rand() < 0.5:\n",
    "                    # X rotations (between hadamard)\n",
    "                    for i in range(dimension * n):\n",
    "                        instructions.append(get_rz(- 2 * gamma * dt, i))\n",
    "\n",
    "                    # penalty term\n",
    "                    for i in range(dimension):\n",
    "                        instructions.append(get_rx(2 * lamb * dt, i * n))\n",
    "                        if encoding == \"unary\":\n",
    "                            instructions.append(get_rx(-2 * lamb * dt, int((i + 1) * n - 1)))\n",
    "                        if encoding == \"antiferromagnetic\":\n",
    "                            instructions.append(get_rx((-1) ** (n) * 2 * lamb * dt, int((i + 1) * n - 1)))\n",
    "                        \n",
    "                        for j in np.arange(i * n, (i + 1) * n - 1):\n",
    "                            if encoding == \"unary\":\n",
    "                                instructions.append(get_rxx(-2 * lamb * dt, [int(j), int(j+1)]))\n",
    "                            elif encoding == \"antiferromagnetic\":\n",
    "                                instructions.append(get_rxx(2 * lamb * dt, [int(j), int(j+1)]))\n",
    "\n",
    "                    # oracle term\n",
    "                    instructions.append(get_rxx(dt / 2, [int(n-1), int(n)]))\n",
    "                    instructions.append(get_rx(dt / 2, n-1))\n",
    "                    instructions.append(get_rx(- dt / 2, n))\n",
    "\n",
    "                    # laplacian correction term\n",
    "                    for i in range(dimension):\n",
    "                        instructions.append(get_rx(-gamma * dt, i * n))\n",
    "                        if encoding == \"unary\":\n",
    "                            instructions.append(get_rx(gamma * dt, int((i + 1) * n - 1)))\n",
    "                        elif encoding == \"antiferromagnetic\":\n",
    "                            instructions.append(get_rx((-1) ** (n+1) * gamma * dt, int((i + 1) * n - 1)))\n",
    "                else:\n",
    "                    # laplacian correction term\n",
    "                    for i in range(dimension):\n",
    "                        instructions.append(get_rx(-gamma * dt, i * n))\n",
    "                        if encoding == \"unary\":\n",
    "                            instructions.append(get_rx(gamma * dt, int((i + 1) * n - 1)))\n",
    "                        elif encoding == \"antiferromagnetic\":\n",
    "                            instructions.append(get_rx((-1) ** (n+1) * gamma * dt, int((i + 1) * n - 1)))\n",
    "\n",
    "                    # oracle term\n",
    "                    instructions.append(get_rxx(dt / 2, [int(n-1), int(n)]))\n",
    "                    instructions.append(get_rx(dt / 2, n-1))\n",
    "                    instructions.append(get_rx(- dt / 2, n))\n",
    "\n",
    "                    # penalty term\n",
    "                    for i in range(dimension):\n",
    "                        instructions.append(get_rx(2 * lamb * dt, i * n))\n",
    "                        if encoding == \"unary\":\n",
    "                            instructions.append(get_rx(-2 * lamb * dt, int((i + 1) * n - 1)))\n",
    "                        if encoding == \"antiferromagnetic\":\n",
    "                            instructions.append(get_rx((-1) ** (n) * 2 * lamb * dt, int((i + 1) * n - 1)))\n",
    "                        \n",
    "                        for j in np.arange(i * n, (i + 1) * n - 1)[::-1]:\n",
    "                            if encoding == \"unary\":\n",
    "                                instructions.append(get_rxx(-2 * lamb * dt, [int(j), int(j+1)]))\n",
    "                            elif encoding == \"antiferromagnetic\":\n",
    "                                instructions.append(get_rxx(2 * lamb * dt, [int(j), int(j+1)]))\n",
    "                                \n",
    "                    # X rotations (between hadamard)\n",
    "                    for i in range(dimension * n):\n",
    "                        instructions.append(get_rz(- 2 * gamma * dt, i))\n",
    "        \n",
    "        instructions += get_hadamard_layer(n, dimension)\n",
    "\n",
    "        return instructions\n",
    "    elif encoding == \"one-hot\":\n",
    "        marked_vertex_index_1 = N-1\n",
    "        marked_vertex_index_2 = 0\n",
    "        for _ in range(r):\n",
    "            if use_second_order_pf:\n",
    "                # Laplacian term\n",
    "                for i in range(dimension):\n",
    "                    for j in np.arange(i * n, (i + 1) * n - 1, 2):\n",
    "                        instructions.append(get_rxx(- 0.5 * gamma * dt, [int(j), int(j+1)]))\n",
    "                        instructions.append(get_ryy(- 0.5 * gamma * dt, [int(j), int(j+1)]))\n",
    "                    for j in np.arange(i * n + 1, (i + 1) * n - 1, 2):\n",
    "                        instructions.append(get_rxx(- 0.5 * gamma * dt, [int(j), int(j+1)]))\n",
    "                        instructions.append(get_ryy(- 0.5 * gamma * dt, [int(j), int(j+1)]))\n",
    "                        \n",
    "                # Laplacian correction term\n",
    "                for i in range(dimension):\n",
    "                    instructions.append(get_rz(gamma * dt, int(i * n)))\n",
    "                    instructions.append(get_rz(gamma * dt, int((i + 1) * n - 1)))\n",
    "\n",
    "                # Oracle term\n",
    "                instructions.append(get_rzz(- dt / 2, [marked_vertex_index_1, n + marked_vertex_index_2]))\n",
    "                instructions.append(get_rz(dt / 2, marked_vertex_index_1))\n",
    "                instructions.append(get_rz(dt / 2, n + marked_vertex_index_2))\n",
    "\n",
    "                # Laplacian term\n",
    "                for i in range(dimension):\n",
    "                    for j in np.arange(i * n + 1, (i + 1) * n - 1, 2):\n",
    "                        instructions.append(get_rxx(- 0.5 * gamma * dt, [int(j), int(j+1)]))\n",
    "                        instructions.append(get_ryy(- 0.5 * gamma * dt, [int(j), int(j+1)]))\n",
    "                    for j in np.arange(i * n, (i + 1) * n - 1, 2):\n",
    "                        instructions.append(get_rxx(- 0.5 * gamma * dt, [int(j), int(j+1)]))\n",
    "                        instructions.append(get_ryy(- 0.5 * gamma * dt, [int(j), int(j+1)]))\n",
    "            else:\n",
    "                if np.random.rand() < 0.5:\n",
    "                    # Laplacian term\n",
    "                    for i in range(dimension):\n",
    "                        for j in np.arange(i * n, (i + 1) * n - 1, 2):\n",
    "                            instructions.append(get_rxx(- gamma * dt, [int(j), int(j+1)]))\n",
    "                            instructions.append(get_ryy(- gamma * dt, [int(j), int(j+1)]))\n",
    "                        for j in np.arange(i * n + 1, (i + 1) * n - 1, 2):\n",
    "                            instructions.append(get_rxx(- gamma * dt, [int(j), int(j+1)]))\n",
    "                            instructions.append(get_ryy(- gamma * dt, [int(j), int(j+1)]))\n",
    "                            \n",
    "                    # Laplacian correction term\n",
    "                    for i in range(dimension):\n",
    "                        instructions.append(get_rz(gamma * dt, int(i * n)))\n",
    "                        instructions.append(get_rz(gamma * dt, int((i + 1) * n - 1)))\n",
    "\n",
    "                    # Oracle term\n",
    "                    instructions.append(get_rzz(- dt / 2, [marked_vertex_index_1, n + marked_vertex_index_2]))\n",
    "                    instructions.append(get_rz(dt / 2, marked_vertex_index_1))\n",
    "                    instructions.append(get_rz(dt / 2, n + marked_vertex_index_2))\n",
    "\n",
    "                else:\n",
    "                    # Oracle term\n",
    "                    instructions.append(get_rzz(- dt / 2, [marked_vertex_index_1, n + marked_vertex_index_2]))\n",
    "                    instructions.append(get_rz(dt / 2, marked_vertex_index_1))\n",
    "                    instructions.append(get_rz(dt / 2, n + marked_vertex_index_2))\n",
    "\n",
    "                    # Laplacian correction term\n",
    "                    for i in range(dimension):\n",
    "                        instructions.append(get_rz(gamma * dt, int(i * n)))\n",
    "                        instructions.append(get_rz(gamma * dt, int((i + 1) * n - 1)))\n",
    "\n",
    "                    # Laplacian term\n",
    "                    for i in range(dimension):\n",
    "                        for j in np.arange(i * n + 1, (i + 1) * n - 1, 2):\n",
    "                            instructions.append(get_rxx(- gamma * dt, [int(j), int(j+1)]))\n",
    "                            instructions.append(get_ryy(- gamma * dt, [int(j), int(j+1)]))\n",
    "                        for j in np.arange(i * n, (i + 1) * n - 1, 2):\n",
    "                            instructions.append(get_rxx(- gamma * dt, [int(j), int(j+1)]))\n",
    "                            instructions.append(get_ryy(- gamma * dt, [int(j), int(j+1)]))\n",
    "        \n",
    "        return instructions\n",
    "    else:\n",
    "        raise ValueError(\"Encoding not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ss(N, dimension, encoding, bitstrings, num_time_points, t_vals, task_name, \n",
    "           gamma, r, num_shots, device, save_dir, use_real_machine, \n",
    "           qpu_job_ids_filename, lamb=None, use_second_order_pf=False,\n",
    "           optimize_circuit=False):\n",
    "    n = num_qubits_per_dim(N, encoding)\n",
    "\n",
    "    job_ids = []\n",
    "\n",
    "    # unnormalized probabilities\n",
    "    sim_freq = np.zeros((num_time_points, N ** dimension))\n",
    "\n",
    "    amplitudes_input = np.ones(N)\n",
    "    amplitudes_input /= np.linalg.norm(amplitudes_input)\n",
    "\n",
    "    for i, t in enumerate(t_vals):\n",
    "        \n",
    "        print(f\"Unitless time: {t : 0.3f}\")\n",
    "\n",
    "        # use braket simulator and get amplitudes of state vector\n",
    "        instructions = state_prep_circuit(N, dimension, amplitudes_input, encoding)\n",
    "        instructions += get_spatial_search_circuit(N, lamb, gamma, t, r, encoding, use_second_order_pf)\n",
    "        if optimize_circuit:\n",
    "            # Optimize with Qiskit\n",
    "            compiled_circuit = transpile(get_qiskit_circuit(n * dimension, instructions), basis_gates=['rxx', 'rx', 'ry', 'rz'], optimization_level=3)\n",
    "            instructions = get_circuit_from_qiskit(compiled_circuit)\n",
    "            \n",
    "        if use_real_machine:\n",
    "            \n",
    "            # Create the job json and save it\n",
    "            job = get_ionq_job_json(task_name, N, dimension, num_shots, device, encoding, instructions, use_native_gates=True)\n",
    "            \n",
    "            print(f\"Saving in {save_dir}\")\n",
    "            with open(join(save_dir, f\"job_{i}.json\"), \"w\") as f:\n",
    "                json.dump(job, f, default=int)\n",
    "\n",
    "            # Send the job and get the job id\n",
    "            job_id = send_job(job)\n",
    "            print(\"Job id:\", job_id)\n",
    "            job_ids.append(job_id)\n",
    "        else:\n",
    "            \n",
    "            native_instructions, qubit_phase = get_native_circuit(dimension * n, instructions)\n",
    "            one_qubit_gate_count, two_qubit_gate_count = get_native_gate_counts(native_instructions)\n",
    "            print(f\"1q gates: {one_qubit_gate_count}, 2q gates: {two_qubit_gate_count}\")\n",
    "            circuit = get_braket_native_circuit(native_instructions)\n",
    "            for j in range(n * dimension):\n",
    "                circuit.rz(j, -qubit_phase[j] * (2 * np.pi))\n",
    "\n",
    "            circuit.amplitude(state=bitstrings)\n",
    "\n",
    "            # Run on simulator\n",
    "            task = device.run(circuit)\n",
    "            # occurrences = get_occurrences(N, task.result().measurements, num_shots, dimension, encoding, periodic=False)\n",
    "            # sim_freq[i] = occurrences.flatten() / np.sum(occurrences)\n",
    "\n",
    "            amplitudes_res = task.result().values[0]\n",
    "            for j in range(N ** dimension):\n",
    "                sim_freq[i,j] = np.abs(amplitudes_res[bitstrings[j]]) ** 2\n",
    "\n",
    "    if use_real_machine:\n",
    "        print(\"Saving IonQ job ids\")\n",
    "        with open(join(save_dir, qpu_job_ids_filename), \"w\") as f:\n",
    "            json.dump(job_ids, f)\n",
    "            f.close()\n",
    "    else:\n",
    "        return sim_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"experiment_data\"\n",
    "TASK_DIR = \"spatial_search\"\n",
    "\n",
    "CURR_DIR = join(\"..\", \"..\", \"..\", DATA_DIR)\n",
    "check_and_make_dir(CURR_DIR)\n",
    "CURR_DIR = join(CURR_DIR, TASK_DIR)\n",
    "check_and_make_dir(CURR_DIR)\n",
    "\n",
    "print(CURR_DIR)\n",
    "\n",
    "use_real_machine = False\n",
    "if use_real_machine:\n",
    "    device = \"qpu.aria-1\"\n",
    "    print(\"Device:\", device)\n",
    "else:\n",
    "    device = LocalSimulator()\n",
    "    print(f\"Using {device.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4\n",
    "encoding = \"unary\"\n",
    "r = 12\n",
    "lamb = 2\n",
    "\n",
    "# N = 5\n",
    "# encoding = \"one-hot\"\n",
    "# r = 5\n",
    "# lamb = None\n",
    "\n",
    "dimension = 2\n",
    "n = num_qubits_per_dim(N, encoding)\n",
    "codewords = get_codewords(N, dimension, encoding, periodic=False)\n",
    "bitstrings = get_bitstrings(N, dimension, encoding)\n",
    "\n",
    "num_time_points = 13\n",
    "num_shots = 200\n",
    "\n",
    "def get_T_2d(N, gamma, H_spatial_search):\n",
    "    dimension = 2\n",
    "    T = N ** dimension\n",
    "    num_time_points = 256\n",
    "    t_vals = np.linspace(0, T, num_time_points)\n",
    "    p = 4 * (np.log(N) / N) ** 2\n",
    "    psi_0 = np.ones(N ** dimension)\n",
    "    psi_0 /= np.linalg.norm(psi_0)\n",
    "\n",
    "    psi = expm_multiply(-1j * H_spatial_search, psi_0, start=0, stop=T, num=num_time_points)\n",
    "    dist = np.abs(psi) ** 2\n",
    "\n",
    "    return t_vals[np.argmax(dist[:,-N] >= p)]\n",
    "\n",
    "# Compute the optimal gamma\n",
    "L = get_laplacian_lattice(N, dimension)\n",
    "marked_vertex_1 = np.zeros(N)\n",
    "marked_vertex_1[0] = 1\n",
    "marked_vertex_2 = np.zeros(N)\n",
    "marked_vertex_2[N-1] = 1\n",
    "\n",
    "marked_vertex = np.kron(marked_vertex_2, marked_vertex_1)\n",
    "H_oracle = -csc_matrix(np.outer(marked_vertex, marked_vertex))\n",
    "# Sign is flipped here; this function minimizes the difference between the two largest eigenvalues of gamma * L + H_oracle\n",
    "gamma = scipy_get_optimal_gamma(L, -H_oracle, 0.3)\n",
    "print(f\"gamma = {gamma}\")\n",
    "H_spatial_search = - gamma * L + H_oracle\n",
    "T = get_T_2d(N, gamma, H_spatial_search)\n",
    "print(f\"T = {T : 0.2f}\")\n",
    "t_vals = np.linspace(0, T, num_time_points)\n",
    "\n",
    "if encoding == \"unary\":\n",
    "    optimize_circuit = True\n",
    "else:\n",
    "    optimize_circuit = False\n",
    "    \n",
    "use_error_mitigation = False\n",
    "# Second order PF generally seems to give better results than randomized first order Trotter\n",
    "use_second_order_pf = True\n",
    "\n",
    "if use_error_mitigation:\n",
    "    assert num_shots >= 500, \"Number of shots should be at least 500\"\n",
    "if not encoding == \"one-hot\":\n",
    "    assert lamb is not None\n",
    "    \n",
    "if encoding == \"one-hot\":\n",
    "    experiment_info = {\n",
    "        \"N\": N,\n",
    "        \"dimension\": dimension,\n",
    "        \"encoding\": encoding,\n",
    "        \"T\": T,\n",
    "        \"num_time_points\": num_time_points,\n",
    "        \"r\": r,\n",
    "        \"num_shots\": num_shots,\n",
    "        \"optimize_circuit\": optimize_circuit,\n",
    "        \"use_error_mitigation\": use_error_mitigation,\n",
    "        \"use_second_order_pf\": use_second_order_pf\n",
    "    }\n",
    "else:\n",
    "    experiment_info = {\n",
    "        \"N\": N,\n",
    "        \"dimension\": dimension,\n",
    "        \"encoding\": encoding,\n",
    "        \"T\": T,\n",
    "        \"num_time_points\": num_time_points,\n",
    "        \"lamb\": lamb,\n",
    "        \"r\": r,\n",
    "        \"num_shots\": num_shots,\n",
    "        \"optimize_circuit\": optimize_circuit,\n",
    "        \"use_error_mitigation\": use_error_mitigation,\n",
    "        \"use_second_order_pf\": use_second_order_pf\n",
    "    }\n",
    "\n",
    "hash_str = hashlib.md5(json.dumps(experiment_info).encode(\"utf-8\")).hexdigest()\n",
    "SAVE_DIR = join(CURR_DIR, hash_str)\n",
    "check_and_make_dir(SAVE_DIR)\n",
    "\n",
    "print(\"Save dir:\", SAVE_DIR)\n",
    "\n",
    "with open(join(SAVE_DIR, \"experiment_info.json\"), \"w\") as f:\n",
    "    json.dump(experiment_info, f)\n",
    "    f.close()\n",
    "\n",
    "name = \"spatial_search\"\n",
    "qpu_job_ids_filename = f'job_ids_qpu.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes_input = np.ones(N)\n",
    "amplitudes_input /= np.linalg.norm(amplitudes_input)\n",
    "instructions = state_prep_circuit(N, dimension, amplitudes_input, encoding)\n",
    "instructions += get_spatial_search_circuit(N, lamb, gamma, T, r, encoding, use_second_order_pf)\n",
    "\n",
    "if optimize_circuit:\n",
    "    # Optimize with Qiskit\n",
    "    compiled_circuit = transpile(get_qiskit_circuit(n * dimension, instructions), basis_gates=['rxx', 'rx', 'ry', 'rz'], optimization_level=3)\n",
    "    instructions = get_circuit_from_qiskit(compiled_circuit)\n",
    "\n",
    "job = get_ionq_job_json(\"\", N, dimension, num_shots, device, encoding, instructions, use_native_gates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_real_machine:\n",
    "    run_ss(N, dimension, encoding, bitstrings, num_time_points, t_vals, TASK_DIR, \n",
    "           gamma, r, num_shots, device, SAVE_DIR, use_real_machine, \n",
    "           qpu_job_ids_filename, lamb=lamb, use_second_order_pf=use_second_order_pf,\n",
    "           optimize_circuit=optimize_circuit)\n",
    "else:\n",
    "    sim_freq = run_ss(N, dimension, encoding, bitstrings, num_time_points, t_vals, TASK_DIR, \n",
    "           gamma, r, num_shots, device, SAVE_DIR, use_real_machine, \n",
    "           qpu_job_ids_filename, lamb=lamb, use_second_order_pf=use_second_order_pf,\n",
    "           optimize_circuit=optimize_circuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data from completed tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ionq_freq = get_results(join(SAVE_DIR, qpu_job_ids_filename), num_time_points, codewords, use_error_mitigation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post processing and figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideal\n",
    "psi_0 = np.ones(N ** dimension, dtype=np.complex64)\n",
    "psi_0 /= np.linalg.norm(psi_0)\n",
    "\n",
    "H = -gamma * L + H_oracle\n",
    "num_time_points_ideal = num_time_points\n",
    "psi = expm_multiply(-1j * H, psi_0, start=0, stop=T, num=num_time_points_ideal)\n",
    "ideal_dist = np.abs(psi) ** 2\n",
    "ideal_success_probability = ideal_dist[:, N ** dimension - N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_freq_normalized = np.zeros_like(sim_freq)\n",
    "for i in range(num_time_points):\n",
    "    if np.sum(sim_freq[i]) > 0:\n",
    "        sim_freq_normalized[i] = sim_freq[i] / np.sum(sim_freq[i])\n",
    "\n",
    "ionq_freq_normalized = np.zeros_like(ionq_freq)\n",
    "for i in range(num_time_points):\n",
    "    if np.sum(ionq_freq[i]) > 0:\n",
    "        ionq_freq_normalized[i] = ionq_freq[i] / np.sum(ionq_freq[i])\n",
    "\n",
    "num_samples_subspace_ionq = np.sum(ionq_freq, axis=1) * num_shots\n",
    "\n",
    "valid_points_sim = np.sum(sim_freq, axis=1) > 0\n",
    "valid_points_ionq = num_samples_subspace_ionq > 0\n",
    "\n",
    "success_prob_sim = sim_freq_normalized[:,-N]\n",
    "success_prob_ionq = ionq_freq_normalized[:,-N]\n",
    "err_ionq = np.sqrt(success_prob_ionq * (1 - success_prob_ionq) / (num_samples_subspace_ionq - 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(ionq_freq_normalized[-1,:].reshape(N,N))\n",
    "plt.title(f\"{N} by {N} lattice ({encoding})\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_and_make_dir(f\"{N}_by_{N}\")\n",
    "\n",
    "with open(join(f\"{N}_by_{N}\", \"experiment_info.json\"), \"w\") as f:\n",
    "    json.dump(experiment_info, f)\n",
    "    f.close()\n",
    "\n",
    "np.savez(join(f\"{N}_by_{N}\", \"data.npz\"), \n",
    "        ideal_dist=ideal_dist,\n",
    "        sim_freq=sim_freq,\n",
    "        ionq_freq=ionq_freq,\n",
    "        ionq_freq_normalized=ionq_freq_normalized,\n",
    "        num_samples_subspace_ionq=num_samples_subspace_ionq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
